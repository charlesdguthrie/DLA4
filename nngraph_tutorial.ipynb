{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "require 'nngraph';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1\n",
       " 2\n",
       " 3\n",
       "[torch.DoubleTensor of size 3]\n",
       "\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.Tensor{1,2,3}\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For whatever reason, the identity module is the first step of every nngraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "module1 = nn.Identity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1\n",
       " 2\n",
       " 3\n",
       "[torch.DoubleTensor of size 3]\n",
       "\n"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "module1:forward(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the extra parentheses. \"The extra () contain properties of this module when embedded into a graph\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x1 = nn.Identity()()\n",
    "m = nn.gModule({x1},{x1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1\n",
       " 2\n",
       " 3\n",
       "[torch.DoubleTensor of size 3]\n",
       "\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m:forward(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Digression: the Oxford tutorial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "add = nn.CAddTable()\n",
    "t1 = torch.Tensor{3,4,10}\n",
    "x=add:forward({a,t1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  4\n",
       "  6\n",
       " 13\n",
       "[torch.DoubleTensor of size 3]\n",
       "\n"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating z = x1 + x1 * linear(x3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 4\n",
       " 6\n",
       " 8\n",
       "[torch.DoubleTensor of size 3]\n",
       "\n"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-- Declare some tensors\n",
    "t1 = torch.Tensor{1,2,3}\n",
    "t2 = torch.Tensor{3,4,5}\n",
    "x1 = nn.Identity()()\n",
    "x2 = nn.Identity()()\n",
    "a = nn.CAddTable()({x1,x2})\n",
    "m = nn.gModule({x1,x2},{a})\n",
    "print(m:forward({t1,t2}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Back to Lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "...rlesguthrie/torch/install/share/lua/5.1/nngraph/init.lua:48: inputs[1] should be an nngraph.Node but is of type torch.DoubleTensor\nstack traceback:\n\t[C]: in function 'error'\n\t...rlesguthrie/torch/install/share/lua/5.1/nngraph/init.lua:48: in function <...rlesguthrie/torch/install/share/lua/5.1/nngraph/init.lua:25>\n\t[C]: at 0x028340c0\n\t[string \"x1 = nn.Identity()()...\"]:3: in main chunk\n\t[C]: in function 'xpcall'\n\t...arlesguthrie/torch/install/share/lua/5.1/itorch/main.lua:179: in function <...arlesguthrie/torch/install/share/lua/5.1/itorch/main.lua:143>\n\t...arlesguthrie/torch/install/share/lua/5.1/lzmq/poller.lua:75: in function 'poll'\n\t...esguthrie/torch/install/share/lua/5.1/lzmq/impl/loop.lua:307: in function 'poll'\n\t...esguthrie/torch/install/share/lua/5.1/lzmq/impl/loop.lua:325: in function 'sleep_ex'\n\t...esguthrie/torch/install/share/lua/5.1/lzmq/impl/loop.lua:370: in function 'start'\n\t...arlesguthrie/torch/install/share/lua/5.1/itorch/main.lua:350: in main chunk\n\t[C]: in function 'require'\n\t(command line):1: in main chunk\n\t[C]: at 0x010234bbb0",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "...rlesguthrie/torch/install/share/lua/5.1/nngraph/init.lua:48: inputs[1] should be an nngraph.Node but is of type torch.DoubleTensor\nstack traceback:\n\t[C]: in function 'error'\n\t...rlesguthrie/torch/install/share/lua/5.1/nngraph/init.lua:48: in function <...rlesguthrie/torch/install/share/lua/5.1/nngraph/init.lua:25>\n\t[C]: at 0x028340c0\n\t[string \"x1 = nn.Identity()()...\"]:3: in main chunk\n\t[C]: in function 'xpcall'\n\t...arlesguthrie/torch/install/share/lua/5.1/itorch/main.lua:179: in function <...arlesguthrie/torch/install/share/lua/5.1/itorch/main.lua:143>\n\t...arlesguthrie/torch/install/share/lua/5.1/lzmq/poller.lua:75: in function 'poll'\n\t...esguthrie/torch/install/share/lua/5.1/lzmq/impl/loop.lua:307: in function 'poll'\n\t...esguthrie/torch/install/share/lua/5.1/lzmq/impl/loop.lua:325: in function 'sleep_ex'\n\t...esguthrie/torch/install/share/lua/5.1/lzmq/impl/loop.lua:370: in function 'start'\n\t...arlesguthrie/torch/install/share/lua/5.1/itorch/main.lua:350: in main chunk\n\t[C]: in function 'require'\n\t(command line):1: in main chunk\n\t[C]: at 0x010234bbb0"
     ]
    }
   ],
   "source": [
    "x1 = nn.Identity()()\n",
    "x2 = nn.Identity()()\n",
    "add = nn.CAddTable()({x1,x2})\n",
    "mul = nn.CMulTable()({add,x1})\n",
    "m = nn.gModule({x1,x2},{mul})\n",
    "print(m:forward({t1,t2}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  4\n",
       " 12\n",
       " 24\n",
       "  1\n",
       "[torch.DoubleTensor of size 4]\n",
       "\n"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.Tensor{1,2,3,1}\n",
    "b = torch.Tensor{3,4,5,0}\n",
    "print(m:forward({a,b}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#A4\n",
    "##nngraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = torch.ones(4)\n",
    "y = torch.ones(5)\n",
    "z = torch.ones(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "--inputs\n",
    "ix = nn.Identity()()\n",
    "iy = nn.Identity()()\n",
    "iz = nn.Identity()()\n",
    "--Wx + b\n",
    "h1 = nn.Linear(4,2)({ix})\n",
    "h2 = nn.Linear(5,2)({iy})\n",
    "-- tanh, sigmoid\n",
    "tanh = nn.Tanh()({h1})\n",
    "sigmoid = nn.Sigmoid()({h2})\n",
    "-- square\n",
    "tsq = nn.Square()({tanh})\n",
    "ssq = nn.Square()({sigmoid})\n",
    "-- cmul\n",
    "cmul = nn.CMulTable()({tsq,ssq})\n",
    "a = nn.CAddTable()({cmul,iz})\n",
    "-- final graph\n",
    "output = nn.gModule({ix,iy,iz},{a})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "h1.data.module.weight = torch.ones(2,4)\n",
    "h1.data.module.bias = torch.ones(2)\n",
    "h2.data.module.weight = torch.ones(2,5)\n",
    "h2.data.module.bias = torch.ones(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1.9949\n",
       " 1.9949\n",
       "[torch.DoubleTensor of size 2]\n",
       "\n"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(output:forward({x,y,z}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "graph.dot(output.fg, 'output','outputBaseName')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##nngraph b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gradOutput = torch.ones(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "foo = {[0]=1,[1]=5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "  0 : 1\n",
       "  1 : 5\n",
       "}\n"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "foo = torch.ones(4,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1  1  1  1\n",
       " 1  1  1  1\n",
       " 1  1  1  1\n",
       " 1  1  1  1\n",
       "[torch.DoubleTensor of size 4x4]\n",
       "\n"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1,.,.) = \n",
       "  1  1\n",
       "  1  1\n",
       "\n",
       "(2,.,.) = \n",
       "  1  1\n",
       "  1  1\n",
       "\n",
       "(3,.,.) = \n",
       "  1  1\n",
       "  1  1\n",
       "\n",
       "(4,.,.) = \n",
       "  1  1\n",
       "  1  1\n",
       "[torch.DoubleTensor of size 4x2x2]\n",
       "\n"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(nn.Reshape(2,2):forward(foo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vm = torch.load('vocab_map.tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iTorch",
   "language": "lua",
   "name": "itorch"
  },
  "language_info": {
   "name": "lua",
   "version": "20100"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
